import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from langgraph.graph import StateGraph, END
from langchain.tools import tool
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
import markdown
from typing import TypedDict, Annotated, List, Dict, Any, Optional
import operator
import json
from docs.S.LangChainå­¦ä¹ è®°å½•.demo.getchat import get_chat


# ===== MCP åè®®å·¥å…·å°è£… =====
@tool
def get_monitoring_data(start_time: str, end_time: str) -> str:
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„ç›‘æ§æ•°æ®"""
    return f"ç›‘æ§æ•°æ®ï¼ˆ{start_time} è‡³ {end_time}ï¼‰: CPUå³°å€¼80%, å†…å­˜ä½¿ç”¨ç‡90%, ç½‘ç»œæµé‡çªå¢"


@tool
def get_change_list(start_time: str, end_time: str) -> str:
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å˜æ›´æ¸…å•"""
    return f"å˜æ›´æ¸…å•ï¼ˆ{start_time} è‡³ {end_time}ï¼‰:\n1. æ•°æ®åº“é…ç½®æ›´æ–°\n2. åº”ç”¨ç‰ˆæœ¬v2.3éƒ¨ç½²\n3. ç½‘ç»œç­–ç•¥è°ƒæ•´"


@tool
def get_query_list(start_time: str, end_time: str) -> str:
    """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ…¢æŸ¥è¯¢åˆ—è¡¨"""
    return f"æ…¢æŸ¥è¯¢åˆ—è¡¨ï¼ˆ{start_time} è‡³ {end_time}ï¼‰:\n1. SELECT * FROM large_table (è€—æ—¶12s)\n2. UPDATE user_stats (è€—æ—¶8s)"


@tool
def rga_search(input_text: str) -> str:
    """ä½¿ç”¨RGAæœç´¢å¼•æ“æ£€ç´¢ç›¸å…³ä¿¡æ¯"""
    return f"RGAæœç´¢ç»“æœ:\n- ç›¸å…³äº‹ä»¶: æ•°æ®åº“ç»´æŠ¤çª—å£\n- ç›¸å…³é…ç½®å˜æ›´: ç´¢å¼•ä¼˜åŒ–\n- ç›¸å…³å‘Šè­¦: æ…¢æŸ¥è¯¢å‘Šè­¦"


@tool
def detect_anomaly(monitoring_data: str) -> str:
    """åˆ†æç›‘æ§æ•°æ®å¹¶æ£€æµ‹æ˜¯å¦å­˜åœ¨å¼‚å¸¸çªåˆº"""
    return "æ£€æµ‹åˆ°å†…å­˜ä½¿ç”¨ç‡å’Œç½‘ç»œæµé‡å­˜åœ¨æ˜æ˜¾çªåˆº"


@tool
def generate_report(analysis_data: str) -> str:
    """æ ¹æ®åˆ†ææ•°æ®ç”Ÿæˆæ ¹å› æŠ¥å‘Š"""
    return "æ ¹å› åˆ†ææŠ¥å‘Š:\n## çªåˆºåˆ†æ\nç›‘æ§æ•°æ®æ˜¾ç¤ºå†…å­˜ä½¿ç”¨ç‡å’Œç½‘ç»œæµé‡å­˜åœ¨æ˜æ˜¾çªåˆº\n## å¯èƒ½åŸå› \n1. æ…¢æŸ¥è¯¢å¯¼è‡´èµ„æºäº‰ç”¨\n2. æ–°ç‰ˆæœ¬åº”ç”¨å†…å­˜æ³„æ¼\n## å»ºè®®\n1. ä¼˜åŒ–æ…¢æŸ¥è¯¢\n2. å›æ»šåº”ç”¨ç‰ˆæœ¬æ£€æŸ¥"


# åˆ›å»ºå·¥å…·åˆ—è¡¨
tools = [
    get_monitoring_data,
    get_change_list,
    get_query_list,
    rga_search,
    detect_anomaly,
    generate_report
]


# ===== MCP åè®®çŠ¶æ€ç»“æ„ =====
class MCPState(TypedDict):
    """MCPåè®®çŠ¶æ€ï¼ŒåŒ…å«æ•´ä¸ªåˆ†æè¿‡ç¨‹çš„ä¿¡æ¯"""
    start_time: str
    end_time: str
    # ä»£ç†æ¶ˆæ¯å†å²
    messages: Annotated[List[Dict[str, Any]], operator.add]
    # ä¸­é—´åˆ†æç»“æœ
    monitoring_data: Optional[str]
    change_list: Optional[str]
    query_list: Optional[str]
    rga_result: Optional[str]
    anomaly_detected: Optional[bool]
    # æœ€ç»ˆæŠ¥å‘Š
    root_cause_report_markdown: Optional[str]
    root_cause_report_html: Optional[str]


# ===== LLM åˆå§‹åŒ– =====
llm = get_chat(model="gpt-4o")


# ===== MCP å·¥å…·å‡½æ•° =====
def markdown_to_html(markdown_text: str) -> str:
    """å°†Markdownè½¬æ¢ä¸ºHTML"""
    return markdown.markdown(markdown_text, extensions=['tables', 'fenced_code'])


def execute_tool(tool_name: str, tool_input: dict) -> str:
    """æ‰§è¡ŒæŒ‡å®šå·¥å…·å¹¶è¿”å›ç»“æœ"""
    for t in tools:
        if t.name == tool_name:
            return t.run(tool_input)
    return f"é”™è¯¯: æ‰¾ä¸åˆ°å·¥å…· {tool_name}"


# ===== æ¶ˆæ¯åºåˆ—åŒ–å‡½æ•° =====
def serialize_message(message: Any) -> Dict:
    """åºåˆ—åŒ–LangChainæ¶ˆæ¯å¯¹è±¡ä¸ºå­—å…¸"""
    if isinstance(message, (HumanMessage, AIMessage, ToolMessage)):
        return {
            "type": type(message).__name__,
            "content": message.content,
            "additional_kwargs": message.additional_kwargs
        }
    return str(message)


def serialize_state(state: Dict) -> Dict:
    """åºåˆ—åŒ–æ•´ä¸ªçŠ¶æ€ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
    serialized = state.copy()

    # åºåˆ—åŒ–æ¶ˆæ¯åˆ—è¡¨
    if "messages" in serialized:
        serialized["messages"] = [serialize_message(msg) for msg in serialized["messages"]]

    return serialized


# ===== åˆ›å»º MCP ä»£ç† =====
# å®šä¹‰ä»£ç†æç¤ºæ¨¡æ¿
prompt = (
    "ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œéœ€è¦é€æ­¥åˆ†ææ€§èƒ½çªåˆºé—®é¢˜ã€‚\n"
    "åˆ†æç­–ç•¥ï¼š\n"
    "1. é¦–å…ˆè·å–ç›‘æ§æ•°æ®äº†è§£åŸºæœ¬æƒ…å†µ\n"
    "2. æ ¹æ®ç›‘æ§ç»“æœå†³å®šæ˜¯å¦éœ€è¦æŸ¥çœ‹å˜æ›´æ¸…å•\n" 
    "3. å¦‚æœå‘ç°æ€§èƒ½é—®é¢˜ï¼Œå†æŸ¥çœ‹æ…¢æŸ¥è¯¢\n"
    "4. å¿…è¦æ—¶ä½¿ç”¨RGAæœç´¢è·å–æ›´å¤šä¿¡æ¯\n"
    "5. æœ€åç”Ÿæˆæ ¹å› åˆ†ææŠ¥å‘Š\n\n"
    "é‡è¦ï¼šæ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…·ï¼ŒåŸºäºç»“æœå†³å®šä¸‹ä¸€æ­¥ï¼\n"
    "å¦‚æœå½“å‰ä¿¡æ¯è¶³å¤Ÿåˆ†æï¼Œç›´æ¥è¾“å‡ºåˆ†æç»“è®ºã€‚"
)

MCP_PROMPT = ChatPromptTemplate.from_messages([
    ("system", prompt),
    MessagesPlaceholder(variable_name="messages"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# åˆ›å»ºä»£ç†
agent = create_openai_tools_agent(
    llm,
    tools,
    MCP_PROMPT
)

# åˆ›å»ºä»£ç†æ‰§è¡Œå™¨
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    return_intermediate_steps=True
)


# ===== MCP ä»£ç†èŠ‚ç‚¹ =====
def agent_node(state: MCPState) -> dict:
    """ä»£ç†èŠ‚ç‚¹ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼ˆè°ƒç”¨å·¥å…·æˆ–ç»“æŸï¼‰"""
    # å‡†å¤‡è¾“å…¥
    input_data = {
        "messages": state["messages"],
        "start_time": state["start_time"],
        "end_time": state["end_time"]
    }

    # è¿è¡Œä»£ç†
    try:
        response = agent_executor.invoke(input_data)
        print(response)
    except Exception as e:
        print(f"âŒ Agentæ‰§è¡Œé”™è¯¯: {e}")
        print(f"ğŸ“ é”™è¯¯ç±»å‹: {type(e)}")
        import traceback
        traceback.print_exc()
        # è¿”å›é”™è¯¯æ¶ˆæ¯ï¼Œç»§ç»­æ‰§è¡Œ
        return {"messages": [AIMessage(content=f"æ‰§è¡Œå‡ºé”™: {str(e)}")]}
        

    # å¤„ç†ä»£ç†å“åº”
    if "output" in response:
        # ä»£ç†å®Œæˆäº†åˆ†æ
        return {
            "messages": [AIMessage(content=response["output"])],
            "root_cause_report_markdown": response["output"]
        }
    elif "intermediate_steps" in response and response["intermediate_steps"]:
        # ä»£ç†è°ƒç”¨äº†å·¥å…·ï¼Œå¤„ç†å·¥å…·ç»“æœ
        last_step = response["intermediate_steps"][-1]
        action, observation = last_step
        tool_name = action.tool

        # ä¿å­˜å·¥å…·ç»“æœåˆ°çŠ¶æ€
        if tool_name == "get_monitoring_data":
            state["monitoring_data"] = observation
        elif tool_name == "get_change_list":
            state["change_list"] = observation
        elif tool_name == "get_query_list":
            state["query_list"] = observation
        elif tool_name == "rga_search":
            state["rga_result"] = observation
        elif tool_name == "detect_anomaly":
            state["anomaly_detected"] = "çªåˆº" in observation

        # åˆ›å»ºå·¥å…·æ¶ˆæ¯
        tool_message = ToolMessage(
            content=json.dumps({"result": observation}),
            name=tool_name
        )

        return {
            "messages": [tool_message]
        }

    # é»˜è®¤è¿”å›
    return {"messages": [AIMessage(content="åˆ†æç»§ç»­...")]}


# ===== MCP æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹ =====
def report_node(state: MCPState) -> dict:
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    if state.get("root_cause_report_markdown"):
        return {
            "root_cause_report_html": markdown_to_html(state["root_cause_report_markdown"])
        }
    return {}


# ===== MCP çŠ¶æ€å›¾æ„å»º =====
graph = StateGraph(MCPState)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("agent", agent_node)
graph.add_node("report", report_node)

# è®¾ç½®å…¥å£ç‚¹
graph.set_entry_point("agent")

# å®šä¹‰è¾¹
graph.add_edge("report", END)


# æ·»åŠ æ¡ä»¶è¾¹
def route_after_agent(state: MCPState) -> str:
    """æ ¹æ®ä»£ç†è¾“å‡ºå†³å®šä¸‹ä¸€æ­¥"""
    if state.get("root_cause_report_markdown"):
        return "report"
    else:
        return "agent"


graph.add_conditional_edges(
    "agent",
    route_after_agent,
    {
        "report": "report",
        "agent": "agent"
    }
)

# ç¼–è¯‘å›¾
mcp_app = graph.compile()

# ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡
graph_png = mcp_app.get_graph().draw_mermaid_png()
with open("plan.png", "wb") as f:
    f.write(graph_png)

# ===== MCP åè®®è¿è¡Œå…¥å£ =====
def run_mcp_analysis(start_time: str, end_time: str) -> Dict:
    """è¿è¡ŒMCPåè®®åˆ†æ"""
    print(f"\nğŸš€ å¼€å§‹MCPåˆ†æ: {start_time} åˆ° {end_time}")
    
    # åˆå§‹çŠ¶æ€
    initial_state = {
        "start_time": start_time,
        "end_time": end_time,
        "messages": [
            HumanMessage(content=f"è¯·åˆ†æä» {start_time} åˆ° {end_time} çš„æ€§èƒ½çªåˆºé—®é¢˜ã€‚")
        ],
        "monitoring_data": None,
        "change_list": None,
        "query_list": None,
        "rga_result": None,
        "anomaly_detected": None,
        "root_cause_report_markdown": None,
        "root_cause_report_html": None
    }

    print(f"ğŸ¯ åˆå§‹çŠ¶æ€è®¾ç½®å®Œæˆ")
    
    # è¿è¡ŒMCPåè®®ï¼Œä½¿ç”¨æµå¼æ‰§è¡Œ
    step_count = 0
    final_state = initial_state
    
    try:
        for state_update in mcp_app.stream(initial_state, {"recursion_limit": 10}):
            step_count += 1
            print(f"\nğŸ“‹ === æ­¥éª¤ {step_count} ===")
            
            for node_name, node_state in state_update.items():
                print(f"ğŸ”„ èŠ‚ç‚¹: {node_name}")
                if "messages" in node_state and node_state["messages"]:
                    for msg in node_state["messages"]:
                        if hasattr(msg, 'content'):
                            print(f"ğŸ’¬ æ¶ˆæ¯: {msg.content[:100]}...")
                        else:
                            print(f"ğŸ’¬ æ¶ˆæ¯: {str(msg)[:100]}...")
                
                # æ›´æ–°æœ€ç»ˆçŠ¶æ€
                final_state.update(node_state)
            
            # æš‚åœä¸€ä¸‹è®©ç”¨æˆ·çœ‹åˆ°è¾“å‡º
            import time
            time.sleep(1)
    
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        
    print(f"\nâœ… MCPåˆ†æå®Œæˆï¼Œæ€»å…±æ‰§è¡Œäº† {step_count} ä¸ªæ­¥éª¤")

    # ç”ŸæˆHTMLæŠ¥å‘Š
    if final_state.get("root_cause_report_markdown"):
        final_state["root_cause_report_html"] = markdown_to_html(
            final_state["root_cause_report_markdown"]
        )

    return final_state


# ===== ä¸»ç¨‹åº =====
if __name__ == "__main__":
    # è¿è¡ŒMCPåˆ†æ
    result = run_mcp_analysis(
        start_time="2025-06-30 12:00",
        end_time="2025-06-30 13:00"
    )

    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 50)
    print("MCPåè®®åˆ†æå®Œæˆï¼")
    print("=" * 50)

    # è¾“å‡ºä¸­é—´ç»“æœ
    print("\nç›‘æ§æ•°æ®:")
    print(result.get("monitoring_data", "æ— "))

    print("\nå˜æ›´æ¸…å•:")
    print(result.get("change_list", "æ— "))

    print("\næ…¢æŸ¥è¯¢åˆ—è¡¨:")
    print(result.get("query_list", "æ— "))

    print("\nRGAæœç´¢ç»“æœ:")
    print(result.get("rga_result", "æ— "))

    # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
    if result.get("root_cause_report_markdown"):
        print("\n" + "=" * 50)
        print("æ ¹å› åˆ†ææŠ¥å‘Š (Markdown):")
        print("=" * 50)
        print(result["root_cause_report_markdown"])

        # ä¿å­˜HTMLæŠ¥å‘Š
        with open("mcp_root_cause_report.html", "w") as f:
            f.write(result["root_cause_report_html"])
        print("\nâœ… HTMLæŠ¥å‘Šå·²ä¿å­˜åˆ° mcp_root_cause_report.html")
    else:
        print("\nâŒ æœªç”Ÿæˆåˆ†ææŠ¥å‘Š")

    # åºåˆ—åŒ–çŠ¶æ€å¹¶ä¿å­˜
    serialized_state = serialize_state(result)
    with open("mcp_analysis_state.json", "w") as f:
        json.dump(serialized_state, f, indent=2, ensure_ascii=False)
    print("âœ… å®Œæ•´åˆ†æçŠ¶æ€å·²ä¿å­˜åˆ° mcp_analysis_state.json")

    # æ‰“å°åºåˆ—åŒ–åçš„æ¶ˆæ¯
    if "messages" in serialized_state:
        print("\næ¶ˆæ¯å†å²:")
        for i, msg in enumerate(serialized_state["messages"]):
            print(f"[æ¶ˆæ¯ {i + 1}] {msg.get('type', 'æœªçŸ¥ç±»å‹')}: {msg.get('content', 'æ— å†…å®¹')}")