# MCP

Model Context Protocol (MCP)

MCP是一个开放协议、他维应用程序想LLM提供上下文的方式进行了标准化。你可以将MCP想象成AI应用程序的USB-C接口。就想USB-C为设备连接各种外设和配件提供了标准化的方式一样，MCP为AI模型链接各种数据源和工具提供了标准化接口

**为什么选择MCP？**

MCP帮助你在LLM的基础上构建代理（agent）和复杂的工作流。LLM经常需要与数据和工具集成，而MCP提供了：
1. 储蓄增长的预构建集成列表，LLM可直接使用
2. 灵活切换不同的LLM提供商合厂商
3. 在你的基础设施内安全地处理数据的最佳时间

**通用架构核心五要素：**

MCP核心采用客户端-服务器架构，主机应用可以连接多个服务器：
1. **MCP Hosts:** 如 Claude Desktop、Cursor、IDE或AI工具，希望通过MCP访问数据的程序
2. **MCP Clients:** 维护与服务器一对一链接的协议客户端
3. **MCP Servers:** 轻量级程序，通过标准的Model Context Protocol 提供特定能力
4. **本都数据库:** MCP服务器可安全访问计算机文件、数据库和服务
5. **远程服务:** MCP服务可链接的互联网上的外部系统（如通过APIs）

**核心MCP概念**
MCP服务可以提供三种主要类型的能力：
1. **Resources:** 可以被clients读取的类文件数据（如API响应或文件内容）
2. **Tools:** 可以被LLM调用的函数（需要用户批准）
3. **Prompt:** 预先编写的模版，帮助用户完成特定的任务

Agent与Tool工具的交互面临的挑战：
**MCP（Model Context Protocol）解决的问题**： Agent需要调用外部工具和API、访问数据库、执行代码等

**A2A（Agent to Agent）解决的问题**：Agent需要理解其他Agent的意图、协同完成任务、与用户进行自然对话
google 25年4月10日发布开源的
[github地址](https://github.com/google-a2a/A2A)


## 面相服务器开发者
开始构建自己的服务器，以便在客户端中使用

在本教程中，我们将构建一个简单的MCP天气服务器，并将其连接到一个host，
服务器会暴漏两个tools: `get-alerts` 和 `get-forecast` 然后我们将服务器连接到一个MCP host


# 官方文档天气查询项目
**设置环境**

首先，安装`uv` 并设置我们的Python项目和环境

``` python
curl -LsSf https://astral.sh/uv/install.sh | sh
```

创建项目：
``` python
# 为我们的项目创建一个新 directory
uv init weather
cd weather

# 创建 virtual environment 并激活它
uv venv
source .venv/bin/activate

# 安装 dependencies
uv add "mcp[cli]" httpx

# 创建我们的 server file
touch weather.py
```

## **构建服务器**
带入packages 并设置 instance
将这些添加到你的 `weather.py`文件的顶部：
``` python
from typing import Any
import httpx
from mcp.server.fastmcp import FastMCP

# 初始化 FastMCP server
mcp = FastMCP("weather")

# Constants
NWS_API_BASE = "https://api.weather.gov"
USER_AGENT = "weather-app/1.0"
```

FastMCP，让我们添加 helper functions，用于查询和格式化来自 National Weather Service API的数据

``` python
async def make_nws_request(url: str) -> dict[str, Any] | None:
    """向 NWS API 发送请求，并进行适当的错误处理。"""
    headers = {
        "User-Agent": USER_AGENT,
        "Accept": "application/geo+json"
    }
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url, headers=headers, timeout=30.0)
            response.raise_for_status()
            return response.json()
        except Exception:
            return None

def format_alert(feature: dict) -> str:
    """将警报 feature 格式化为可读的字符串。"""
    props = feature["properties"]
    return f"""
事件: {props.get('event', 'Unknown')}
区域: {props.get('areaDesc', 'Unknown')}
严重性: {props.get('severity', 'Unknown')}
描述: {props.get('description', 'No description available')}
指示: {props.get('instruction', 'No specific instructions provided')}
"""
```
实现 tool execution
Tool execution handler 负责实际执行每个Tool的逻辑：

``` python
@mcp.tool()
async def get_alerts(state: str) -> str:
    """获取美国州的天气警报。

    Args:
        state: 两个字母的美国州代码（例如 CA、NY）
    """
    url = f"{NWS_API_BASE}/alerts/active/area/{state}"
    data = await make_nws_request(url)

    if not data or "features" not in data:
        return "无法获取警报或未找到警报。"

    if not data["features"]:
        return "该州没有活跃的警报。"

    alerts = [format_alert(feature) for feature in data["features"]]
    return "\n---\n".join(alerts)

@mcp.tool()
async def get_forecast(latitude: float, longitude: float) -> str:
    """获取某个位置的天气预报。

    Args:
        latitude: 位置的纬度
        longitude: 位置的经度
    """
    # 首先获取预报网格 endpoint
    points_url = f"{NWS_API_BASE}/points/{latitude},{longitude}"
    points_data = await make_nws_request(points_url)

    if not points_data:
        return "无法获取此位置的预报数据。"

    # 从 points response 中获取预报 URL
    forecast_url = points_data["properties"]["forecast"]
    forecast_data = await make_nws_request(forecast_url)

    if not forecast_data:
        return "无法获取详细预报。"

    # 将 periods 格式化为可读的预报
    periods = forecast_data["properties"]["periods"]
    forecasts = []
    for period in periods[:5]:  # 仅显示接下来的 5 个 periods
        forecast = f"""
{period['name']}:
温度: {period['temperature']}°{period['temperatureUnit']}
风: {period['windSpeed']} {period['windDirection']}
预报: {period['detailedForecast']}
"""
        forecasts.append(forecast)

    return "\n---\n".join(forecasts)
```

**运行server**

最后让我们初始化并运行server
``` python
if __name__ == "__main__":
    # 初始化并运行 server
    mcp.run(transport='stdio')
```


## **面向客户端开发者**
开始构建可以与所有MCP 服务器集成的客户端

首先，使用 uv 创建一个新的 Python 项目：
``` python 
# 创建项目目录
uv init mcp-client
cd mcp-client

# 创建虚拟环境
uv venv

# 激活虚拟环境
# 在 Windows 上：
.venv\Scripts\activate
# 在 Unix 或 MacOS 上：
source .venv/bin/activate

# 安装所需的包
uv add mcp anthropic python-dotenv

# 删除样板文件
rm main.py

# 创建我们的主文件
touch client.py
```


**设置你的 API 密钥**
你需要从 [Anthropic Console](https://console.anthropic.com/settings/keys) 获取 Anthropic API 密钥。

创建一个 .env 文件来存储它：
```
# 创建 .env 文件
touch .env
```

将你的密钥添加到 .env 文件中：
```
ANTHROPIC_API_KEY=<your key here>
```

**创建客户端**


客户端初始化
- MCPClient 类使用会话管理和API客户端进行初始化
- 使用 AsyncExitStack 进行适当的资源管理
- 配置Anthropic 客户端已进行Claude交互

``` python 
import asyncio
from typing import Optional
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# from anthropic import Anthropic
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()  # 从 .env 加载环境变量

class MCPClient:
    def __init__(self):
        # 初始化会话和客户端对象
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        # self.anthropic = Anthropic()
        self.llm = ChatOpenAI(
            model="claude-3-7-sonnet-20250219",
            openai_api_key=os.getenv("ANTHROPIC_API_KEY"),  # 这里用你的 Anthropic Key
            base_url="https://globalai.vip/v1"
        )
    # 方法将在这里添加
```

**服务器连接管理**
- 支持Python和Node.js服务器
- 验证服务器脚本类型
- 设置适当的通信通道
- 初始化会话并列出可用工具
``` python 
async def connect_to_server(self, server_script_path: str):
    """连接到 MCP 服务器

    Args:
        server_script_path: 服务器脚本的路径 (.py 或 .js)
    """
    is_python = server_script_path.endswith('.py')
    is_js = server_script_path.endswith('.js')
    if not (is_python or is_js):
        raise ValueError("服务器脚本必须是 .py 或 .js 文件")

    command = "python" if is_python else "node"
    server_params = StdioServerParameters(
        command=command,
        args=[server_script_path],
        env=None
    )

    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
    self.stdio, self.write = stdio_transport
    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))

    await self.session.initialize()

    # 列出可用的工具
    response = await self.session.list_tools()
    tools = response.tools
    print("\n已连接到服务器，工具包括：", [tool.name for tool in tools])
```
**查询处理逻辑**
- 维护对话上下文
- 处理 Claude的响应和工具调用
- 管理 Claude和工具之间的消息流
- 将结果组合成连贯的响应
``` python 
async def process_query(self, query: str) -> str:
    """使用 Claude 和可用的工具处理查询"""
    messages = [
        {
            "role": "user",
            "content": query
        }
    ]

    response = await self.session.list_tools()
    available_tools = [{
        "name": tool.name,
        "description": tool.description,
        "input_schema": tool.inputSchema
    } for tool in response.tools]

    # 初始 Claude API 调用
    response = self.anthropic.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1000,
        messages=messages,
        tools=available_tools
    )

    # 处理响应并处理工具调用
    final_text = []

    assistant_message_content = []
    for content in response.content:
        if content.type == 'text':
            final_text.append(content.text)
            assistant_message_content.append(content)
        elif content.type == 'tool_use':
            tool_name = content.name
            tool_args = content.input

            # 执行工具调用
            result = await self.session.call_tool(tool_name, tool_args)
            final_text.append(f"[调用工具 {tool_name}，参数 {tool_args}]")

            assistant_message_content.append(content)
            messages.append({
                "role": "assistant",
                "content": assistant_message_content
            })
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "tool_result",
                        "tool_use_id": content.id,
                        "content": result.content
                    }
                ]
            })

            # 获取 Claude 的下一个响应
            response = self.anthropic.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                messages=messages,
                tools=available_tools
            )

            final_text.append(response.content[0].text)

    return "\n".join(final_text)
```

**交互式聊天页面**
- 提供简单的命令行界面
- 处理用户输入并显示响应
- 包含基本的错误处理
- 允许优雅退出

资源管理
- 适当清理资源-处理链接问题的错误处理
- 优雅的关闭程序

``` python 
async def chat_loop(self):
    """运行交互式聊天循环"""
    print("\nMCP 客户端已启动！")
    print("输入你的查询或输入 'quit' 退出。")

    while True:
        try:
            query = input("\n查询: ").strip()

            if query.lower() == 'quit':
                break

            response = await self.process_query(query)
            print("\n" + response)

        except Exception as e:
            print(f"\n错误: {str(e)}")

async def cleanup(self):
    """清理资源"""
    await self.exit_stack.aclose()
```

**主入口点**


``` python 
async def main():
    if len(sys.argv) < 2:
        print("使用方法: python client.py <path_to_server_script>")
        sys.exit(1)

    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    import sys
    asyncio.run(main())
```


# 推荐的 MCP Servers

1. 数据库操作： mysqldb-mcp-server
2. 网页数据采集：Firecrawl
3. 记忆图谱：memory  基于知识图谱的长期记忆系统用于维护上下文
  