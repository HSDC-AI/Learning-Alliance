"""
ä¿®æ”¹ç‰ˆçš„ AgentExecutor - é›†æˆyieldæµå¼å¤„ç†
å±•ç¤ºå¦‚ä½•åœ¨ç°æœ‰A2Aç³»ç»Ÿä¸­æ­£ç¡®ä½¿ç”¨yield
"""

import asyncio
import logging
import json

from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.utils import new_agent_text_message, new_data_artifact

from .streaming_agent import StreamingAgentExecutor

logger = logging.getLogger(__name__)


class StreamingOrchestratorAgentExecutor(AgentExecutor):
    """
    ä½¿ç”¨yieldçš„ç¼–æ’å™¨Agentæ‰§è¡Œå™¨
    è¿™æ˜¯åœ¨A2Aç³»ç»Ÿä¸­æ­£ç¡®ä½¿ç”¨yieldçš„æ–¹å¼
    """

    def __init__(self):
        # ä½¿ç”¨æµå¼å¤„ç†å™¨
        self.streaming_processor = StreamingAgentExecutor()
        logger.info("ğŸ­ StreamingAgentExecutor åˆå§‹åŒ–å®Œæˆ")

    async def execute(
        self,
        context: RequestContext,
        event_queue: EventQueue,
    ) -> None:
        """
        æ‰§è¡Œç¼–æ’ä»»åŠ¡ - ä½¿ç”¨yieldå®ç°æµå¼å“åº”
        è¿™æ˜¯Agentå†…éƒ¨æ­£ç¡®ä½¿ç”¨yieldçš„å…³é”®æ–¹æ³•
        """
        logger.info(f"ğŸ“¨ æ”¶åˆ°ç¼–æ’ä»»åŠ¡: {context.task_id}")

        try:
            # è§£æç”¨æˆ·æ¶ˆæ¯
            user_message = ""
            if context.request.params.message and context.request.params.message.parts:
                user_message = " ".join([
                    part.text for part in context.request.params.message.parts
                    if hasattr(part, 'text')
                ])

            session_id = context.request.params.session_id or context.task_id
            logger.info(f"ğŸ“ ç”¨æˆ·è¯·æ±‚: {user_message}")
            logger.info(f"ğŸ”– ä¼šè¯ID: {session_id}")

            # ğŸŒŸ å…³é”®ï¼šè¿™é‡Œä½¿ç”¨yieldæµå¼å¤„ç†å™¨
            # æ¯æ¬¡yieldéƒ½ä¼šå®æ—¶å‘é€çŠ¶æ€ç»™å®¢æˆ·ç«¯
            async for update in self.streaming_processor.process_resources_stream(user_message, session_id):

                # æ ¹æ®æ›´æ–°ç±»å‹å†³å®šå¦‚ä½•å‘é€ç»™å®¢æˆ·ç«¯
                await self._handle_stream_update(update, event_queue)

                # å¯é€‰ï¼šè®°å½•è¯¦ç»†æ—¥å¿—
                logger.info(f"æµå¼æ›´æ–°: {update['type']} - {update['message']} ({update.get('progress', 'N/A')}%)")

            logger.info(f"âœ… ç¼–æ’ä»»åŠ¡å®Œæˆ: {context.task_id}")

        except Exception as e:
            logger.error(f"âŒ ç¼–æ’ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

            # å‘é€é”™è¯¯æ¶ˆæ¯
            await event_queue.enqueue_event(
                new_agent_text_message(f"âŒ ç¼–æ’å™¨æ‰§è¡Œå¤±è´¥: {str(e)}")
            )

            # å‘é€é”™è¯¯è¯¦æƒ…
            error_result = {
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__,
                "task_id": context.task_id
            }

            await event_queue.enqueue_event(
                new_data_artifact(
                    data=error_result,
                    artifact_type="application/json",
                    title="error_details"
                )
            )

    async def _handle_stream_update(self, update: dict, event_queue: EventQueue) -> None:
        """
        å¤„ç†æµå¼æ›´æ–° - å°†yieldçš„ç»“æœè½¬æ¢ä¸ºå®¢æˆ·ç«¯æ¶ˆæ¯
        è¿™å±•ç¤ºäº†yieldåœ¨Agentå†…éƒ¨çš„å®é™…åº”ç”¨
        """

        update_type = update.get("type")
        message = update.get("message", "")
        progress = update.get("progress", 0)
        data = update.get("data", {})

        # 1. å‘é€è¿›åº¦æ¶ˆæ¯
        if update_type in [
            "workflow_start",
            "step_start",
            "step_complete",
            "workflow_complete",
            "workflow_error"
        ]:
            # é‡è¦é‡Œç¨‹ç¢‘ - æ€»æ˜¯å‘é€
            progress_text = f"[{progress}%] {message}" if progress >= 0 else message
            await event_queue.enqueue_event(
                new_agent_text_message(progress_text)
            )

        elif update_type in [
            "sub_agent_progress",
            "batch_progress",
            "file_operation"
        ]:
            # è¯¦ç»†è¿›åº¦ - é€‰æ‹©æ€§å‘é€ï¼ˆé¿å…æ¶ˆæ¯è¿‡å¤šï¼‰
            if progress > 0 and progress % 20 == 0:  # æ¯20%å‘é€ä¸€æ¬¡
                progress_text = f"[{progress}%] {message}"
                await event_queue.enqueue_event(
                    new_agent_text_message(progress_text)
                )

        # 2. å‘é€ç»“æ„åŒ–æ•°æ®
        if update_type in ["step_complete", "workflow_complete"] and data:
            # å‘é€JSONç»“æœæ•°æ®
            try:
                await event_queue.enqueue_event(
                    new_data_artifact(
                        data=data,
                        artifact_type="application/json",
                        title=f"{update.get('step_name', 'result')}_data"
                    )
                )
            except Exception as e:
                logger.warning(f"âš ï¸ å‘é€æ•°æ®å¤±è´¥: {e}")

        # 3. ç‰¹æ®Šå¤„ç†
        if update_type == "workflow_complete":
            # å·¥ä½œæµå®Œæˆ - å‘é€æœ€ç»ˆæ€»ç»“
            summary = data.get("summary", {})
            if summary:
                summary_text = f"""
                        ğŸ¯ **å¤„ç†ç»“æœæ€»ç»“:**
                        - ğŸ“ åˆ†æç»“æœ: {summary.get('analysis', '')} 
                        - â±ï¸ å·¥ä½œæµID: {summary.get('workflow_id', 'N/A')}
                        - ğŸ• å¼€å§‹æ—¶é—´: {summary.get('start_time', 'N/A')}
                        - ğŸ•• ç»“æŸæ—¶é—´: {summary.get('end_time', 'N/A')}
                """.strip()

                await event_queue.enqueue_event(
                    new_agent_text_message(summary_text)
                )

        elif update_type == "workflow_error":
            # é”™è¯¯å¤„ç† - å‘é€é”™è¯¯è¯¦æƒ…
            if data:
                await event_queue.enqueue_event(
                    new_data_artifact(
                        data=data,
                        artifact_type="application/json",
                        title="error_details"
                    )
                )

    async def cancel(
        self,
        context: RequestContext,
        event_queue: EventQueue
    ) -> None:
        """å–æ¶ˆç¼–æ’ä»»åŠ¡"""
        logger.info(f"ğŸ›‘ å–æ¶ˆç¼–æ’ä»»åŠ¡: {context.task_id}")
        await event_queue.enqueue_event(
            new_agent_text_message("ğŸ›‘ ç¼–æ’ä»»åŠ¡å·²å–æ¶ˆ")
        )


# ç®€åŒ–çš„å•ä¸€åŠŸèƒ½Agentç¤ºä¾‹ï¼Œå±•ç¤ºyieldçš„åŸºæœ¬ä½¿ç”¨
class SimpleStreamingAgent:
    """
    ç®€å•çš„æµå¼Agentç¤ºä¾‹
    å±•ç¤ºyieldåœ¨å•ä¸€Agentä¸­çš„åŸºæœ¬ä½¿ç”¨æ¨¡å¼
    """

    async def process_files(self) -> dict:
        """
        å¤„ç†æ‰€æœ‰è°ƒåº¦ä»»åŠ¡ - ä½¿ç”¨yieldæä¾›å®æ—¶è¿›åº¦
        è¿™æ˜¯Agentå†…éƒ¨ä½¿ç”¨yieldçš„æœ€åŸºæœ¬æ¨¡å¼
        """

        # æœ€ç»ˆç»“æœ
        yield {
            "type": "completion",
            "message": "è°ƒåº¦ä»»åŠ¡å¤„ç†å®Œæˆ",
            "progress": 100,
        }

class SimpleStreamingAgentExecutor(AgentExecutor):
    """
    ç®€å•çš„æµå¼AgentExecutorç¤ºä¾‹
    å±•ç¤ºyieldçš„æœ€åŸºæœ¬é›†æˆæ–¹å¼
    """

    def __init__(self):
        self.agent = SimpleStreamingAgent()

    async def execute(
        self,
        context: RequestContext,
        event_queue: EventQueue,
    ) -> None:
        """æ‰§è¡Œç®€å•çš„æµå¼å¤„ç†"""

        # ğŸŒŸ ä½¿ç”¨Agentçš„yieldæ–¹æ³•
        async for update in self.agent.process_files():

            # å‘é€è¿›åº¦æ¶ˆæ¯
            message_text = f"[{update['progress']}%] {update['message']}"
            await event_queue.enqueue_event(
                new_agent_text_message(message_text)
            )

            # å®Œæˆæ—¶å‘é€ç»“æœæ•°æ®
            if update["type"] == "completion":
                await event_queue.enqueue_event(
                    new_data_artifact(
                        data=update["result"],
                        artifact_type="application/json",
                        title="processing_result"
                    )
                )

    async def cancel(
        self,
        context: RequestContext,
        event_queue: EventQueue
    ) -> None:
        """å–æ¶ˆå¤„ç†"""
        await event_queue.enqueue_event(
            new_agent_text_message("ğŸ›‘ å¤„ç†å·²å–æ¶ˆ")
        )