"""
Streaming Resource Processor - ä½¿ç”¨yieldå®ç°æµå¼å¤„ç†çš„Agentæ ¸å¿ƒé€»è¾‘
å±•ç¤ºåœ¨Agentå†…éƒ¨å¦‚ä½•æ­£ç¡®ä½¿ç”¨yield
"""

import asyncio
import logging
import uuid
from typing import Dict, Any, Optional, AsyncGenerator
from datetime import datetime
import os
import httpx

from a2a.client import A2ACardResolver, A2AClient
from a2a.utils import new_agent_text_message, new_data_artifact
from a2a.types import MessageSendParams, SendMessageRequest

logger = logging.getLogger(__name__)


class StreamingCoordinatorAgent:
    """æµå¼èµ„æºå¤„ç†ç¼–æ’å™¨ - åœ¨Agentå†…éƒ¨ä½¿ç”¨yield"""

    def __init__(self):
        # Agentæ³¨å†Œè¡¨
        self.agent_registry = {
            "data_collector": os.getenv("DATA_COLLECTOR_URL", "http://localhost:10000"),
        }

        logger.info("ğŸ­ StreamingCoordinatorAgent åˆå§‹åŒ–å®Œæˆ")

    async def process_resources_stream(self, user_message: str, session_id: str) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†èµ„æºçš„æ ¸å¿ƒæ–¹æ³• - è¿™æ˜¯Agentå†…éƒ¨ä½¿ç”¨yieldçš„æ­£ç¡®æ–¹å¼
        æ¯ä¸ªå¤„ç†æ­¥éª¤éƒ½é€šè¿‡yieldè¿”å›çŠ¶æ€ç»™å®¢æˆ·ç«¯
        """

        workflow_id = str(uuid.uuid4())
        start_time = datetime.now()

        # æ­¥éª¤0: åˆå§‹åŒ–
        yield {
            "type": "workflow_start",
            "workflow_id": workflow_id,
            "message": "ğŸ­ ç¼–æ’å™¨å·²å¯åŠ¨ï¼Œå¼€å§‹åè°ƒèµ„æºå¤„ç†å·¥ä½œæµ",
            "progress": 0,
            "timestamp": start_time.isoformat(),
            "data": {
                "user_message": user_message,
                "session_id": session_id,
                "available_agents": list(self.agent_registry.keys())
            }
        }

        try:
            # æ­¥éª¤1: èµ„æºåˆ†æ (0-30%)
            yield {
                "type": "step_start",
                "step_name": "analyzing_monitor_data",
                "message": "ğŸ“Š æ­¥éª¤1: å¼€å§‹ç›‘æ§æ•°æ®åˆ†æ",
                "progress": 100,
                "timestamp": datetime.now().isoformat(),
                "data": {"target_agent": "data_collector"}
            }

            # è°ƒç”¨èµ„æºåˆ†æAgent - è¿™é‡Œä¹Ÿä¼šæœ‰å­è¿›åº¦
            async for sub_progress in self._call_agent_stream("data_collector", user_message, session_id):
                # å°†å­Agentçš„è¿›åº¦è½¬æ¢ä¸ºæ•´ä½“è¿›åº¦ (10-30%)
                overall_progress = 10 + (sub_progress.get("progress", 0) * 0.2)

                yield {
                    "type": "sub_agent_progress",
                    "step_name": "analyzing_monitor_data",
                    "agent_name": "data_collector",
                    "message": f"ğŸ“Š èµ„æºåˆ†æ: {sub_progress.get('message', '')}",
                    "progress": int(overall_progress),
                    "timestamp": datetime.now().isoformat(),
                    "data": sub_progress.get("data", {})
                }

            # å·¥ä½œæµå®Œæˆ
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            final_result = {
                "workflow_id": workflow_id,
                "status": "success",
                "duration": duration
            }

            yield {
                "type": "workflow_complete",
                "step_name": "completed",
                "message": "ğŸ‰ èµ„æºå¤„ç†å·¥ä½œæµå®Œæˆï¼",
                "progress": 100,
                "timestamp": end_time.isoformat(),
                "data": final_result
            }

        except Exception as e:
            error_time = datetime.now()
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")

            yield {
                "type": "workflow_error",
                "step_name": "error",
                "message": f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "progress": -1,
                "timestamp": error_time.isoformat(),
                "data": {
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "workflow_id": workflow_id
                }
            }

    async def _call_agent_stream(self, agent_name: str, message: str, session_id: str) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è°ƒç”¨å­Agentå¹¶è¿”å›æµå¼è¿›åº¦
        è¿™å±•ç¤ºäº†Agenté—´é€šä¿¡ä¸­çš„yieldä½¿ç”¨
        """

        if agent_name not in self.agent_registry:
            yield {
                "status": "error",
                "message": f"Agent {agent_name} æœªæ³¨å†Œ",
                "progress": 0,
                "data": {"error": f"Agent {agent_name} not found"}
            }
            return

        agent_url = self.agent_registry[agent_name]

        # è¿æ¥Agent
        yield {
            "status": "connecting",
            "message": f"æ­£åœ¨è¿æ¥åˆ° {agent_name}...",
            "progress": 10,
            "data": {"agent_url": agent_url}
        }

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                # è·å–Agentå¡ç‰‡
                yield {
                    "status": "resolving",
                    "message": f"æ­£åœ¨è·å– {agent_name} çš„Agentå¡ç‰‡...",
                    "progress": 30,
                    "data": {"action": "get_agent_card"}
                }

                resolver = A2ACardResolver(
                    httpx_client=client,
                    base_url=agent_url
                )

                try:
                    agent_card = await resolver.get_agent_card()

                    yield {
                        "status": "connected",
                        "message": f"å·²è¿æ¥åˆ° {agent_name}: {agent_card.name}",
                        "progress": 50,
                        "data": {
                            "agent_name": agent_card.name,
                            "agent_description": agent_card.description
                        }
                    }

                except Exception as e:
                    yield {
                        "status": "connection_failed",
                        "message": f"è¿æ¥ {agent_name} å¤±è´¥: {str(e)}",
                        "progress": 0,
                        "data": {"error": str(e)}
                    }
                    return

                # å‘é€æ¶ˆæ¯
                yield {
                    "status": "sending_request",
                    "message": f"æ­£åœ¨å‘ {agent_name} å‘é€è¯·æ±‚...",
                    "progress": 70,
                    "data": {"message_length": len(message)}
                }

                # æ¨¡æ‹ŸAgentå¤„ç†æ—¶é—´
                await asyncio.sleep(1)

                yield {
                    "status": "processing",
                    "message": f"{agent_name} æ­£åœ¨å¤„ç†è¯·æ±‚...",
                    "progress": 90,
                    "data": {"agent": agent_name}
                }

                await asyncio.sleep(1)

                # æ¨¡æ‹Ÿå“åº”
                mock_response = {
                    "agent": agent_name,
                    "result": "success",
                    "data": f"Processed by {agent_name}"
                }

                yield {
                    "status": "completed",
                    "message": f"âœ… {agent_name} å¤„ç†å®Œæˆ",
                    "progress": 100,
                    "data": {
                        "response": mock_response,
                        "agent": agent_name
                    }
                }

        except Exception as e:
            yield {
                "status": "error",
                "message": f"è°ƒç”¨ {agent_name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "progress": 0,
                "data": {
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "agent": agent_name
                }
            }


# è¿™æ˜¯å¦‚ä½•åœ¨AgentExecutorä¸­ä½¿ç”¨ä¸Šé¢çš„æµå¼å¤„ç†å™¨
class StreamingAgentExecutor:
    """å±•ç¤ºå¦‚ä½•åœ¨AgentExecutorä¸­æ­£ç¡®ä½¿ç”¨yield"""

    def __init__(self):
        self.processor = StreamingCoordinatorAgent()

    async def execute_with_streaming(self, user_message: str, session_id: str, event_queue):
        """
        åœ¨AgentExecutorä¸­ä½¿ç”¨yieldå¤„ç†å™¨çš„æ­£ç¡®æ–¹å¼
        è¿™é‡Œæ¥æ”¶yieldçš„ç»“æœå¹¶é€šè¿‡event_queueå‘é€ç»™å®¢æˆ·ç«¯
        """

        async for update in self.processor.process_resources_stream(user_message, session_id):
            # å°†yieldçš„æ¯ä¸ªæ›´æ–°è½¬æ¢ä¸ºAgentæ¶ˆæ¯å‘é€ç»™å®¢æˆ·ç«¯

            if update["type"] in ["workflow_start", "step_start", "step_complete", "workflow_complete"]:
                # é‡è¦çš„é‡Œç¨‹ç¢‘æ¶ˆæ¯
                message_text = f"[{update['progress']}%] {update['message']}"
                await event_queue.enqueue_event(
                    new_agent_text_message(message_text)
                )

            elif update["type"] in ["sub_agent_progress", "batch_progress", "file_operation"]:
                # è¯¦ç»†è¿›åº¦æ¶ˆæ¯ï¼ˆå¯é€‰æ‹©æ€§å‘é€ï¼Œé¿å…æ¶ˆæ¯è¿‡å¤šï¼‰
                if update["progress"] % 10 == 0:  # æ¯10%å‘é€ä¸€æ¬¡
                    message_text = f"[{update['progress']}%] {update['message']}"
                    await event_queue.enqueue_event(
                        new_agent_text_message(message_text)
                    )

            elif update["type"] == "workflow_error":
                # é”™è¯¯æ¶ˆæ¯
                await event_queue.enqueue_event(
                    new_agent_text_message(update['message'])
                )

            # å¯ä»¥é€‰æ‹©åœ¨æŸäº›å…³é”®ç‚¹å‘é€JSONæ•°æ®
            if update["type"] in ["workflow_complete", "step_complete"]:
                await event_queue.enqueue_event(
                    new_data_artifact(
                        data=update["data"],
                        artifact_type="application/json",
                        title=f"{update['step_name']}_result"
                    )
                )

            # åœ¨çœŸå®ç³»ç»Ÿä¸­ï¼Œä½ ä¹Ÿå¯ä»¥è®°å½•æ—¥å¿—ã€æ›´æ–°æ•°æ®åº“ç­‰
            logger.info(f"å·¥ä½œæµæ›´æ–°: {update['type']} - {update['message']} ({update['progress']}%)")